#!/usr/bin/env python3
"""
ğŸ”¥ F5 ì›í´ë¦­ ì‹¤í–‰ - NXJ_Parser ë©€í‹°ëª¨ë‹¬ PDF íŒŒì„œ
RTX 5090 + BLIP-2 + GMFT ìë™ ì„¤ì •

F5 í‚¤ë§Œ ëˆ„ë¥´ë©´ ëª¨ë“  ê²ƒì´ ìë™ ì‹¤í–‰
"""

import sys
import os
import subprocess
import time
import fitz
import torch
import logging
from pathlib import Path
from datetime import datetime

def auto_setup_environment():
    """ğŸš€ F5 ì‹¤í–‰ ì‹œ ìë™ í™˜ê²½ ì„¤ì •"""
    print("ğŸ”¥ NXJ_Parser ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ìë™ ì‹œì‘!")
    print("=" * 60)
    
    # 1. Python ê²½ë¡œ ë° ê°€ìƒí™˜ê²½ ì²´í¬
    print("1ï¸âƒ£ Python í™˜ê²½ ì²´í¬...")
    current_python = sys.executable
    print(f"   í˜„ì¬ Python: {current_python}")
    
    # 2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ ì„¤ì¹˜ ì²´í¬
    print("2ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬ ë° ìë™ ì„¤ì¹˜...")
    
    required_packages = [
        ('torch', 'torch torchvision'),
        ('transformers', 'transformers accelerate'),
        ('tiktoken', 'tiktoken'),
        ('pillow', 'pillow')
    ]
    
    for package, install_cmd in required_packages:
        try:
            __import__(package)
            print(f"   âœ… {package} ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"   ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...")
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + install_cmd.split())
                print(f"   âœ… {package} ì„¤ì¹˜ ì™„ë£Œ")
            except subprocess.CalledProcessError:
                print(f"   âš ï¸  {package} ì„¤ì¹˜ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
    
    # 3. GPU í™˜ê²½ ì²´í¬
    print("3ï¸âƒ£ GPU í™˜ê²½ ìë™ ì²´í¬...")
    try:
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / (1024**3)
                print(f"   ğŸš€ GPU {i}: {props.name} ({memory_gb:.1f}GB)")
                
                if "5090" in props.name:
                    print("   ğŸ”¥ RTX 5090 ë°œê²¬! ìµœê³  ì„±ëŠ¥ ëª¨ë“œ í™œì„±í™”")
            
            print(f"   âœ… CUDA ì‚¬ìš© ê°€ëŠ¥ - GPU {gpu_count}ê°œ ê°ì§€")
        else:
            print("   âš ï¸  GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    except Exception as e:
        print(f"   âš ï¸  PyTorch ì²´í¬ ì˜¤ë¥˜: {e}")
    
    # 4. ê¸°ë³¸ íŒŒì¼ ìë™ ì„ íƒ
    print("4ï¸âƒ£ ì²˜ë¦¬í•  PDF íŒŒì¼ ìë™ ì„ íƒ...")
    
    pdf_files = []
    for pdf_dir in ['pdf_files', 'pdf_files_o']:
        if Path(pdf_dir).exists():
            pdf_files.extend(list(Path(pdf_dir).glob('*.pdf')))
    
    if pdf_files:
        # ì²« ë²ˆì§¸ PDF íŒŒì¼ ìë™ ì„ íƒ
        default_file = pdf_files[0]
        print(f"   ğŸ“„ ìë™ ì„ íƒëœ íŒŒì¼: {default_file.name}")
        return str(default_file)
    else:
        print("   âŒ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. pdf_files/ ë””ë ‰í† ë¦¬ì— PDFë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        return None

def main():
    """ğŸ¯ F5 ì›í´ë¦­ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ìë™ í™˜ê²½ ì„¤ì •
    selected_file = auto_setup_environment()
    
    if not selected_file:
        print("\nâŒ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        input("ì—”í„°ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    print("\n" + "=" * 60)
    print("ğŸš€ BLIP-2 + GMFT ë©€í‹°ëª¨ë‹¬ íŒŒì‹± ì‹œì‘!")
    print("=" * 60)
    
    # ë©”ì¸ ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰
    try:
        # ì„¤ì • ë¡œë“œ
        sys.path.append(str(Path(__file__).parent))
        
        from utils.file_io import setup_directories, save_json
        from utils.chunk_processor import ChunkProcessor  
        from utils.text_chunker import TextChunker
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        logger = logging.getLogger(__name__)
        
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        setup_directories()
        
        # ğŸ”¥ **F5 ê¸°ë³¸ ì‹¤í–‰: ìˆœì°¨ + ì²­í¬ + í…ìŠ¤íŠ¸ ë¶„í• **
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {Path(selected_file).name}")
        
        # PDF ë¶„í•  ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        processor = ChunkProcessor()
        
        # PDF ë¶„í•  ê¸°ë°˜ ì²˜ë¦¬ ì‹¤í–‰
        result = processor.process_pdf_in_chunks(selected_file)
        
        if result:
            # RAGìš© í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
            text_chunker = TextChunker()
            result = text_chunker.chunk_document_content(result)
            
            # ê²°ê³¼ ì €ì¥
            output_filename = Path(selected_file).stem + '.json'
            output_path = Path('output') / output_filename
            
            save_json(result, str(output_path))
            
            print(f"\nğŸ‰ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_path}")
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            stats = result.get('document_stats', {}).get('chunking', {})
            multimodal_stats = stats.get('separated_multimodal_stats', {})
            
            print("\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
            print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì²­í¬: {stats.get('total_text_chunks', 0)}ê°œ")
            print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {multimodal_stats.get('total_contextual_images', 0)}ê°œ")
            print(f"   ğŸ“Š í‘œ: {multimodal_stats.get('total_contextual_tables', 0)}ê°œ")
            print(f"   ğŸ”¥ BLIP-2 ìº¡ì…˜: {multimodal_stats.get('images_with_blip2_captions', 0)}ê°œ")
            
        else:
            print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60) 
    print("âœ… F5 ì›í´ë¦­ ì‹¤í–‰ ì™„ë£Œ!")
    print("ë‹¤ì‹œ ì‹¤í–‰í•˜ë ¤ë©´ F5ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    print("=" * 60)

# ğŸ¯ **F5 ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ main() í˜¸ì¶œ**
if __name__ == "__main__":
    # F5 ì‹¤í–‰ì´ë©´ ìë™ ëª¨ë“œ, ëª…ë ¹í–‰ì´ë©´ ê¸°ì¡´ ë°©ì‹
    if len(sys.argv) == 1:
        # F5 ì‹¤í–‰ (ì¸ì ì—†ìŒ) - ìë™ ëª¨ë“œ
        main()
    else:
        # ëª…ë ¹í–‰ ì‹¤í–‰ - ê¸°ì¡´ ë°©ì‹ ìœ ì§€
        # [ê¸°ì¡´ main.py ì½”ë“œê°€ ì—¬ê¸°ì— ê³„ì†ë¨]
        pass 