#!/usr/bin/env python3
"""GPU í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import torch
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
import time

def test_gpu():
    print("ğŸ”¥ GPU í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # CUDA í™•ì¸
    if not torch.cuda.is_available():
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€")
        return False
    
    device = torch.device('cuda')
    print(f"âœ… ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
    
    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"ì´ GPU ë©”ëª¨ë¦¬: {total_memory:.1f}GB")
    
    # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
    print("í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸...")
    x = torch.randn(1000, 1000).to(device)
    y = torch.randn(1000, 1000).to(device)
    start_time = time.time()
    z = torch.matmul(x, y)
    end_time = time.time()
    print(f"í–‰ë ¬ ê³±ì…ˆ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    allocated = torch.cuda.memory_allocated() / 1024**3
    print(f"í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.2f}GB")
    
    return True

if __name__ == "__main__":
    test_gpu()
