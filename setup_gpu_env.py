#!/usr/bin/env python3
"""
NXJ ì„œë²„ GPU í™˜ê²½ ì„¤ì • ì²´í¬ ë° ê°€ì´ë“œ
"""

import sys
import subprocess
import os
from pathlib import Path

def check_python_env():
    print("ğŸ Python í™˜ê²½ í™•ì¸")
    print("=" * 50)
    print(f"Python ë²„ì „: {sys.version}")
    print(f"Python ê²½ë¡œ: {sys.executable}")
    
    # ê°€ìƒí™˜ê²½ í™•ì¸
    if hasattr(sys, 'prefix') and hasattr(sys, 'base_prefix'):
        in_venv = sys.prefix != sys.base_prefix
        print(f"ê°€ìƒí™˜ê²½ ì‚¬ìš© ì¤‘: {in_venv}")
        if in_venv:
            print(f"ê°€ìƒí™˜ê²½ ê²½ë¡œ: {sys.prefix}")
    
    return True

def check_torch_cuda():
    print("\nğŸ”¥ PyTorch CUDA ì§€ì› í™•ì¸")
    print("=" * 50)
    
    try:
        import torch
        print(f"PyTorch ë²„ì „: {torch.__version__}")
        
        if hasattr(torch.version, 'cuda') and torch.version.cuda:
            print(f"CUDA ë²„ì „: {torch.version.cuda}")
        else:
            print("âŒ CPU ì „ìš© PyTorch ì„¤ì¹˜ë¨")
            return False
            
        cuda_available = torch.cuda.is_available()
        print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {cuda_available}")
        
        if cuda_available:
            device_count = torch.cuda.device_count()
            print(f"GPU ê°œìˆ˜: {device_count}")
            
            for i in range(device_count):
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / (1024**3)
                print(f"  GPU {i}: {props.name} ({memory_gb:.1f}GB)")
        
        return cuda_available
        
    except ImportError:
        print("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        return False

def check_nvidia_driver():
    print("\nğŸš— NVIDIA ë“œë¼ì´ë²„ í™•ì¸")
    print("=" * 50)
    
    try:
        # nvidia-smi ì‹¤í–‰
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            lines = result.stdout.split('\n')
            for line in lines:
                if 'Driver Version' in line:
                    print(f"ë“œë¼ì´ë²„ ë²„ì „ ë°œê²¬: {line.strip()}")
                    return True
            print("âœ… nvidia-smi ì‹¤í–‰ ì„±ê³µ")
            return True
        else:
            print("âŒ nvidia-smi ì‹¤í–‰ ì‹¤íŒ¨")
            return False
    except FileNotFoundError:
        print("âŒ nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return False
    except Exception as e:
        print(f"âŒ nvidia-smi ì˜¤ë¥˜: {e}")
        return False

def check_transformers():
    print("\nğŸ¤— Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸")
    print("=" * 50)
    
    try:
        import transformers
        print(f"Transformers ë²„ì „: {transformers.__version__}")
        
        # BLIP-2 ê´€ë ¨ ëª¨ë“ˆ í™•ì¸
        try:
            from transformers import Blip2Processor, Blip2ForConditionalGeneration
            print("âœ… BLIP-2 ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥")
            return True
        except ImportError as e:
            print(f"âŒ BLIP-2 ëª¨ë“ˆ ì˜¤ë¥˜: {e}")
            return False
            
    except ImportError:
        print("âŒ Transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        return False

def generate_setup_commands():
    print("\nğŸ› ï¸  GPU í™˜ê²½ ì„¤ì • ëª…ë ¹ì–´")
    print("=" * 50)
    
    print("# 1. CUDA ì§€ì› PyTorch ì„¤ì¹˜ (RTX 5090ìš©)")
    print("pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n# 2. BLIP-2 í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬")
    print("pip install transformers accelerate")
    
    print("\n# 3. ì¶”ê°€ GPU ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬")
    print("pip install xformers  # ë©”ëª¨ë¦¬ ìµœì í™”")
    print("pip install bitsandbytes  # ì–‘ìí™” ì§€ì›")
    
    print("\n# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í•„ìš”ì‹œ)")
    print("export CUDA_VISIBLE_DEVICES=0")
    print("export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512")

def create_gpu_test_script():
    print("\nğŸ§ª GPU í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
    print("=" * 50)
    
    test_script = '''#!/usr/bin/env python3
"""GPU í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import torch
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
import time

def test_gpu():
    print("ğŸ”¥ GPU í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # CUDA í™•ì¸
    if not torch.cuda.is_available():
        print("âŒ CUDA ì‚¬ìš© ë¶ˆê°€")
        return False
    
    device = torch.device('cuda')
    print(f"âœ… ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
    
    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"ì´ GPU ë©”ëª¨ë¦¬: {total_memory:.1f}GB")
    
    # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸
    print("í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸...")
    x = torch.randn(1000, 1000).to(device)
    y = torch.randn(1000, 1000).to(device)
    start_time = time.time()
    z = torch.matmul(x, y)
    end_time = time.time()
    print(f"í–‰ë ¬ ê³±ì…ˆ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    allocated = torch.cuda.memory_allocated() / 1024**3
    print(f"í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.2f}GB")
    
    return True

if __name__ == "__main__":
    test_gpu()
'''
    
    with open('test_gpu.py', 'w') as f:
        f.write(test_script)
    
    print("âœ… test_gpu.py ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
    print("ì‹¤í–‰: python test_gpu.py")

def main():
    print("ğŸš€ NXJ ì„œë²„ GPU í™˜ê²½ ì„¤ì • ì²´í¬")
    print("=" * 60)
    
    # í™˜ê²½ ì²´í¬
    python_ok = check_python_env()
    cuda_ok = check_torch_cuda()
    driver_ok = check_nvidia_driver()
    transformers_ok = check_transformers()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ ì²´í¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"Python í™˜ê²½: {'âœ…' if python_ok else 'âŒ'}")
    print(f"PyTorch CUDA: {'âœ…' if cuda_ok else 'âŒ'}")
    print(f"NVIDIA ë“œë¼ì´ë²„: {'âœ…' if driver_ok else 'âŒ'}")
    print(f"Transformers: {'âœ…' if transformers_ok else 'âŒ'}")
    
    if all([python_ok, cuda_ok, driver_ok, transformers_ok]):
        print("\nğŸ‰ ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ë°”ë¡œ BLIP-2 + GMFT ë©€í‹°ëª¨ë‹¬ íŒŒì‹±ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("\nì‹¤í–‰ ëª…ë ¹ì–´:")
        print("python main.py --force --single [íŒŒì¼ëª…]")
    else:
        print("\nâš ï¸  ì¶”ê°€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        generate_setup_commands()
    
    create_gpu_test_script()

if __name__ == "__main__":
    main() 